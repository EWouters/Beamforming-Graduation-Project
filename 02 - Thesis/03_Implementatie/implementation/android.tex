\documentclass[a4paper, notitlepage]{report}
\input{../title}
\input{../preamble}
\begin{document}

\section{Android app}
\label{sec:android}
For acquiring the microphone signals, as well as auxiliary data such as the smartphone orientation, a smartphone application (or `app') was developed on the Android platform.

In the context of the Android Application Programming Interface\footnote{The Android Application Programming Interface (or `API') is referenced throughout this section. Documentation for this API is available on-line at \url{https://developer.android.com/reference/packages.html}.}, this application consists of two parts. The first is an Activity, which is started by the user and can be interacted with using the phone's display, and the second is a Service, which runs independently from the Activity so that its operation can continue if the phone's display is off or another Activity has focus. 

A screenshot of the Activity is shown in Fig.~\ref{fig:app-activity}. It shows the phone ID as sent along when connecting to the \matlab server, and provides fields for setting the hostname and port of that server. After this information has been entered, the user can press the `Start service' button to start the Service in the background, and the `Stop service' button to terminate it again.

\begin{figure}[hbt]
	\centering 
		\includegraphics[width=0.25\paperwidth]{figures/measurementapp_activity_crop.png}
		\caption[Android Activity user interface.]{Partial screenshot of the Activity user interface}
		\label{fig:app-activity}
\end{figure}

The Service consists of four separate classes. There is a RecordService that provides the main Service seen by the Android OS. It handles start and stop requests from the Activity or the OS itself, as well as some convenience methods for notifying the user and interacting with the Android user interface. The Service sets itself up as a so-called `foreground service', which implies that it is a purposefully started activity that should take priority over background processes when the system is low on resources.

\paragraph*{}
The bulk of the application is distributed over three threads started by this Service. The NetworkInterfaceThread handles the connection to the \matlab server and loops to receive new messages, as well as sending messages generated by the other threads. As there is only one connection to the server, it was decided to use Java's normal blocking socket system, meaning the thread blocks (and other threads can be run) while no new data has been received.

The NetworkInterfaceThread follows the same state machine described in section \ref{sec:io_fsm} for the \matlab server. When the thread is started, its state is \textsc{setup}. When it has received a packet containing the audio settings for this session, it transmits an acknowledgement packet and changes state to \textsc{idle}. From this point on, it will process a command to start streaming by going into the \textsc{streaming} state, at which point it launches an AudioThread to acquire data from the on-board microphone. During both the \textsc{idle} and \textsc{streaming} states, an OrientationThread is run to acquire orientation data, which is also transferred to the \matlab server.

\paragraph*{}
The AudioThread uses the Android AudioRecord API to initialize the device microphone. As the Android API defines a number of different audio sources meant for different applications \footnote{For more information, see \url{https://developer.android.com/reference/android/media/MediaRecorder.AudioSource.html}.}, it accepts an input argument specifying the audio source to use as a byte. Once the audio source has been successfully initialized, the thread continuously does a blocking read from the audio device into a buffer of its own. Once it has enough samples to transmit a full block (of the length sent by the server), it calls a method in the NetworkInterfaceThread to initiate this transmission. 

\paragraph*{}
The OrientationThread uses the Android SensorManager API to request access to the device magnetometer and accelerometer. The magnetometer produces a vector in the direction of the local magnetic field, and the accelerometer produces a vector in the direction of the so-called `proper acceleration', taking into account the balance of gravitational force and restoration force of the table surface. As such, the magnetometer should produce a vector that points north, and the accelerometer should, at rest, produce a vector that points down.

These vectors are then processed using Android's provided SensorManager.getRotationMatrix to yield a rotation and inclination matrix. These matrices represent the transformation from the device coordinate system (in which the accelerometer and magnetometer measure) to a global coordinate system where X points east, Y points towards magnetic North, and Z points towards the ground. In appendix \ref{app:coordinate_system}, this coordinate system is shown graphically. Finally, the SensorManager.getOrientation method is then called on this matrix to express this transformation in an azimuth, pitch and roll angle that can be sent to the server.

\end{document}
